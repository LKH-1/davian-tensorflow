{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Convolutional Neural Networks\n",
    "이번 시간에는 간단하게 CNN을 구현해 보도록 하겠습니다. 이번 시간 역시 mnist를 가지고 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n",
      "x_train:  (55000, 784)\n",
      "y_train:  (55000, 10)\n",
      "x_test:  (10000, 784)\n",
      "y_test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./mnist\", one_hot=True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "print \"x_train: \", x_train.shape\n",
    "print \"y_train: \", y_train.shape\n",
    "print \"x_test: \", x_test.shape\n",
    "print \"y_test: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter setting \n",
    "\n",
    "이제 CNN에 들어갈 각종 parameter들을 설정합니다. 통상적으로 CNN에는 다음과 같은 parameter들이 필요합니다.\n",
    "- learning rate\n",
    "- batch size\n",
    "  * CNN을 학습할 때 가장 좋은 방법은 N개의 샘플이 있는 데이터를 한꺼번에 input으로 넣어서 학습하는 건데, training set이 50000개 이렇게 되면 메모리 문제가 발생할 수 있습니다. 그래서 할수없이 데이터를 가령 500개씩 분할(minibatch)로 나눠서 학습을 하게 됩니다. 이렇게 되면 50000개를 한번에 학습하는 대신, 500개만을 넣은 모델을 학습하고, 같은 모델을 다음 500개의 데이터로 다시 학습하는 걸 100번 하는 식으로 진행이 됩니다.\n",
    "- training iterations 혹은 number of epochs\n",
    "- input size \n",
    "  * 통상적으로 이미지를 행렬로 나타낼 때 [H(높이),W(너비),D(RGB)]로 나타냅니다. MNIST는 28x28의 흑백이미지이므로 input size는 28x28x1=784가 되고, CIFAR-10의 경우 32x32x10, imageNet은 224x224x3 등으로 해상도에 따라 달라집니다.\n",
    "- number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 100\n",
    "display_step = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input & Output, 그리고 사용되는 dropout값을 담기 위한 placeholder를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # to keep dropout probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 내부에 사용되는 filter(=layer)(=weight) 및 bias들을 Variable의 형태로 생성합니다.\n",
    "- 얘네가 굳이 Variable인 이유는 CNN을 학습할 때 backpropagation을 계산하면서 값들을 매번 업데이트해줘야 하기 때문입니다.\n",
    "- weight랑 bias를 생성할 때, 내가 원하는 CNN이 어떻게 convolution 혹은 pooling을 하면서 input과 output matrix의 크기가 어떻게 달라지는지를 매번 계산해야 합니다. 마지막에 fully connected layer를 만들 때에는 계산이 복잡해질 수 있는데, 뒤에 이를 좀 더 쉽게 하는 법이 나옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Network Implementation **\n",
    "\n",
    "이제 CNN architecture를 한번 구현해 보겠습니다. 우리 CNN은 다음과 같은 간단한 구조를 가집니다.\n",
    "\n",
    "1) 5x5 convolution (x32)\n",
    "\n",
    "2) ReLU\n",
    "\n",
    "3) Max pooling\n",
    "\n",
    "4) 5x5 convolution (x64)\n",
    "\n",
    "5) ReLU\n",
    "\n",
    "6) Max pooling\n",
    "\n",
    "7) Fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모든 과정은 TF library 의 함수 6개만 알면 됩니다.\n",
    "\n",
    "1) tf.nn.conv2d(input, weights, strides, padding)\n",
    "- 용도: 원본 layer 부분부분마다 필터를 대고 2-D convolution을 진행해서 output layer를 만든다.\n",
    "* input: 원본 이미지의 placeholder 혹은 전 단계의 결과\n",
    "* weights: 아까 tf.Variable로 만들어놓은, 해당 단계에 써야 하는 weight\n",
    "* strides: [1,int,int,1]이나 대개 [1,1,1,1]로 합니다.\n",
    "* padding: 'SAME' 혹은 'VALID'가 있는데 거의 다 'SAME' 씁니다. ('SAME'이 zero padding 허용)\n",
    "\n",
    "2) tf.nn.max_pool(input, ksize, strides, padding)\n",
    "- 용도: window를 이미지에다 대고 해당 window 내 가장 큰 값만 반환하면서 축소된 layer를 만든다.\n",
    "* input: 원본 이미지의 placeholder 혹은 전 단계의 결과\n",
    "* ksize: [1,int,int,1], 여기서 int에는 1/int로 배율을 줄일 지를 나타냅니다.\n",
    "* strides: [1,int,int,1]이나 대개 ksize랑 똑같이 맞춥니다.\n",
    "* padding: 역시 'SAME'으로 맞춥시다. ('SAME'이 zero padding 허용)\n",
    "\n",
    "3) tf.nn.bias_add(input, bias_layer)\n",
    "- 용도: bias를 더해준다 (Wx+b의 b를 더해주는 겁니다)\n",
    "* input: 그냥 인풋\n",
    "* bias_layer: 앞서 weight와 함께 정의한 해당 bias입니다.\n",
    "\n",
    "4) tf.nn.relu(input)\n",
    "- 용도: nonlinearity를 만들어주기 위해, 가장 많이 쓰이는 ReLU 함수를 원본 layer에다 적용합니다.\n",
    "* input: 역시 그냥 인풋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CNN(x, weights, biases, dropout):\n",
    "    \n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    print \"Input x:               \", x.get_shape().as_list()\n",
    "\n",
    "    # 1st Convolution Layer\n",
    "    conv1 = tf.nn.conv2d(x, weights['wc1'], strides=[1,1,1,1], padding='SAME')\n",
    "    print \"After 1st conv:        \", conv1.get_shape().as_list()\n",
    "    conv1 = tf.nn.bias_add(conv1, biases['bc1'])\n",
    "    print \"After adding bias:     \", conv1.get_shape().as_list()\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    print \"After ReLU:            \", conv1.get_shape().as_list()\n",
    "    # Max Pooling (down-sampling)\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    print \"After 1st max_pooling: \", pool1.get_shape().as_list()\n",
    "\n",
    "    # 2nd Convolution Layer\n",
    "    conv2 = tf.nn.conv2d(pool1, weights['wc2'], strides=[1,1,1,1], padding='SAME')\n",
    "    print \"After 2nd conv:        \", conv2.get_shape().as_list()\n",
    "    conv2 = tf.nn.bias_add(conv2, biases['bc2'])\n",
    "    print \"After adding bias:     \", conv2.get_shape().as_list()\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    print \"After ReLU:            \", conv2.get_shape().as_list()\n",
    "    # Max Pooling (down-sampling)\n",
    "    pool2 = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    print \"After 2nd max_pooling: \", pool2.get_shape().as_list()\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(pool2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    print \"Fully connected:       \", fc1.get_shape().as_list()\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    print \"Output:                \", out.get_shape().as_list()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Optimization **\n",
    "\n",
    "이제 CNN 모델의 구조를 지었으니, 실제로 결과를 출력하게끔 해야죠.\n",
    "위의 def CNN이 결과물로 [None,10]을 뱉어냈는데, 이제 loss를 계산하고 optimize를 해야죠.\n",
    "구조는 다음과 같습니다.\n",
    "\n",
    "1) pred : 각 input을 넣었을 때 10개의 class에 대한 값들이 저장되어 있다\n",
    "  - a: [100,10]라고 하자\n",
    "  - a[0,0]=0.18, a[0,1]=0.02, a[0,2]=0.95, ..., a[0,9]=0.37 이런 식이면 a[0]이라는 샘플은 [2]에 해당하는 label, 즉 '1'일 거라고 예측\n",
    "  \n",
    "2) 예측한 pred와 실제 y를 받아서 softmax 계산을 하고 loss를 반환하는 cost. y 역시 [100,10]여야 한다.\n",
    "\n",
    "3) 그 cost를 인풋으로 받고, cost를 최대한으로 줄이기 위한 함수를 실행하는 optimizer를 생성한다.\n",
    "- optimizer들 종류는 다음과 같다. 아니, 더 많다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x:                [None, 28, 28, 1]\n",
      "After 1st conv:         [None, 28, 28, 32]\n",
      "After adding bias:      [None, 28, 28, 32]\n",
      "After ReLU:             [None, 28, 28, 32]\n",
      "After 1st max_pooling:  [None, 14, 14, 32]\n",
      "After 2nd conv:         [None, 14, 14, 64]\n",
      "After adding bias:      [None, 14, 14, 64]\n",
      "After ReLU:             [None, 14, 14, 64]\n",
      "After 2nd max_pooling:  [None, 7, 7, 64]\n",
      "Fully connected:        [None, 1024]\n",
      "Output:                 [None, 10]\n"
     ]
    }
   ],
   "source": [
    "# Construct model\n",
    "pred = CNN(x, weights, biases, keep_prob)\n",
    "# Define loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "# Define optimizer\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# 다른 optimizer들도 한번 넣어보세요\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.AdadeltaOptimizer().minimize(cost)\n",
    "#optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.5).minimize(cost)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Performance metric **\n",
    "\n",
    "다음 함수들을 이용해서 accuracy를 측정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find correct prediction\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "# Get accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연구실에서 서버 돌릴 때 꿀팁, GPU 사용 관련 커맨드 알려드립니다\n",
    "\n",
    "1) 사용방법: tf.Session 혹은 tf.InteractiveSession의 argument로 해당 config 추가\n",
    "\n",
    "2) tf.ConfigProto 커맨드\n",
    "  - log_device_placement=True : 어느 device를 사용하는지를 알기 위한 device mapping입니다.\n",
    "  - allow_soft_placement=True : device를 설정했는데 해당 device가 없어서 (혹은 메모리가 다 차서) 안 돌아갈 \n",
    "    수 있는데, 이 커맨드를 통해 그런 문제를 방지할 수 있습니다.\n",
    "  - 제 경우에는 allow_soft_placement=True로 하니까, GPU로 지원되지 않는 단순 연산도 GPU가 하려고 하다 보니 발생하는 에러를 줄일 수 있었습니다. 사용범위를 유기적으로 조정하지 않을까 생각합니다.\n",
    "\n",
    "  ### tf.GPUOptions 커맨드\n",
    "      - (1) ** allow_growth=True ** : Tensorflow에서는 디폴트로 사용가능한 모든 메모리를 할당하는데, 이렇게 되면 mnist 하나 돌린다고 11기가씩 잡아먹을 수 있습니다. 이를 방지하기 위해 allow_growth=True로 하면 필요한 만큼의 메모리만 먹습니다.\n",
    "        - 11749MiB->461MiB\n",
    "      - (2) ** per_process_gpu_memory_fraction=0.1 ** : 역시 이 커맨드를 켜면 GPU 최대 메모리 중 0.1, 즉 10%만을\n",
    "      사용한다는 뜻입니다. 돌려야 하는 네트워크가 allow_growth로도 많은 메모리를 잡아먹게 되면 이 커맨드를\n",
    "      통해 강제할당할 수 있습니다. 필요에 맞게 퍼센트를 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.1)\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True,\n",
    "                        gpu_options=gpu_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20000, Minibatch Loss= 1273.430664, Training Accuracy= 0.91000\n",
      "Iter 40000, Minibatch Loss= 185.872345, Training Accuracy= 0.96000\n",
      "Iter 60000, Minibatch Loss= 250.748138, Training Accuracy= 0.95000\n",
      "Iter 80000, Minibatch Loss= 264.887146, Training Accuracy= 0.95000\n",
      "Iter 100000, Minibatch Loss= 1.893320, Training Accuracy= 0.99000\n",
      "Iter 120000, Minibatch Loss= 161.823471, Training Accuracy= 0.96000\n",
      "Iter 140000, Minibatch Loss= 27.044228, Training Accuracy= 0.99000\n",
      "Iter 160000, Minibatch Loss= 118.369102, Training Accuracy= 0.99000\n",
      "Iter 180000, Minibatch Loss= 7.695849, Training Accuracy= 0.99000\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# apply config when starting session\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "init.run()\n",
    "step = 1\n",
    "\n",
    "while step * batch_size < training_iters:\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    # Run optimization\n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "    if step % display_step == 0:\n",
    "    # Calculate batch loss and accuracy\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "    step += 1\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Testing Accuracy:', 0.98828125)\n"
     ]
    }
   ],
   "source": [
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "                                      y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
